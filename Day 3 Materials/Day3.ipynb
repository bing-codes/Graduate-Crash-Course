{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d39fa40",
   "metadata": {},
   "source": [
    "# Day 3 -- Python for Researchers\n",
    "\n",
    "## Today's Goals:\n",
    "   * Use the pandas library\n",
    "   * Understand what a dataframe and series are\n",
    "   * Learn how to execute basic data cleaning\n",
    "   * Learn some key functions for data analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585427e4",
   "metadata": {},
   "source": [
    "**Introduction to Pandas**\n",
    "\n",
    "Pandas is the industry standard data analysis library. It lets us convert raw datasets (typically a .csv file) into something called a *dataframe*. A dataframe looks like a spreadsheet, but is actually optimized to allow you to handle large datasets quickly and efficiently. We can use pandas to clean, analyze, and even visualize our data. \n",
    "\n",
    "In pandas you can work with two kinds of objects -- a dataframe, or a 2D array (something with rows and columns) or a series, a 1D array (or just a  singular column). Both of these objects comes with different built-in functions that we will explore throughout today's lesson. \n",
    "\n",
    "Pandas is a really powerful tool for researchers. Oftentimes, the way you really learn to master it is by looking at examples and reading documentation. They have a [\"10 Minutes to Pandas\"](https://pandas.pydata.org/docs/user_guide/10min.html) guide we recommend you return to after this week "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924b6a70",
   "metadata": {},
   "source": [
    "#### Section 1: Our first dataset \n",
    "\n",
    "To start our exploration of pandas, we're going to use a Film Permits dataset from the [NYC Open Data site](https://data.cityofnewyork.us/City-Government/Film-Permits/tg4x-b46p/about_data). That dataset is already in our Day 3 folder. Please note: when you gather a dataset online, it typically comes with it's own internal logic -- especially goverment datasets -- so you will want to study any documentation they provide to better undersatnd your data. \n",
    "\n",
    "In order to use pandas, you always have to import it. The common way to do this is to \"import pandas as pd\" -- pd just is a shorter amout of letters to type in. \n",
    "\n",
    "To create your dataframe, you run the code below. Our dataframe is being stored in the variable permits_df. Take a second to study the output, what can we learn from it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a14a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "permits_df = pd.read_csv(\"Film_Permits_20250518.csv\")\n",
    "\n",
    "permits_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb713187",
   "metadata": {},
   "source": [
    "**Learning about our dataset**\n",
    "\n",
    "We're going to use four techniques to learn about our dataset:\n",
    "\n",
    "  * info() -- tells you how many rows and columns there are; the names of each column; the different kinds of datatype contained in the columns; and how many non-null values there are in each column\n",
    "  * head() -- shows by default the top five rows, you can add an optional parameter (a number) to show more\n",
    "  * tail() -- same as head(), except it shows you the bottom rows\n",
    "  * .dtypes -- tells you what each column's data type is\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a418ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "permits_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451f73e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "permits_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72143f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "permits_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064c5ff3",
   "metadata": {},
   "source": [
    "Note that there are seven datatypes in pandas, some of which correspond to the datatypes in Python:\n",
    "\n",
    "* object (equivalent to a Python string)\n",
    "* int64 (integer)\n",
    "* float64 (float aka decimal)\n",
    "* bool (Boolean, True/False values)\n",
    "* datetime64 (date and time values)\n",
    "* timedelta[ns] (differences between two values)\n",
    "* category (finite list of text values, corresponds to categorical variables in statistics)\n",
    "\n",
    "It's important to know what types of data you are manipulating, because they all come with unique abilities and limitations.\n",
    "\n",
    "What kind of datatypes does our dataframe contain? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300c0e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "permits_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de27099",
   "metadata": {},
   "source": [
    "We can also access specific information in our dataframe. The most frequent way you will do this is to isolate a column. \n",
    "\n",
    "The preferred syntax for this is to use brackets and input the column name as strings. You can isolate only one at a time, \n",
    "or isolate multiple by writing them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad50742",
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolating one column\n",
    "permits_df[\"Borough\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff46324b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolating multiple columns\n",
    "permits_df[[\"EventID\", \"Borough\", \"Category\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6666de3b",
   "metadata": {},
   "source": [
    "If you want to isolate very specific information, you can use .iloc and .loc\n",
    "\n",
    " * You use .loc when dealing with column names (labels), e.g., below isolates the first six rows in the EventType column (label), notice it uses inclusive slicing\n",
    " * You use .iloc when you want to index a specific row and column (iloc stands of “integer location”),\n",
    "   e.g., below isolates the same thing using index numbers and uses exclusive slicing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafdb9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of loc\n",
    "\n",
    "permits_df.loc[:5, \"EventType\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e19eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of iloc\n",
    "\n",
    "permits_df.iloc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fe6692",
   "metadata": {},
   "source": [
    "**Preparing our dataset for analysis**\n",
    "\n",
    "Here's our research question: *How many of each film permit type was distributed in each borough?* Because this dataset was produced by NYC, it's pretty clean. We just want to drop the columns that don't help us answer our research question so that we can save memory. It's not a huge dataset, so this isn't necessary, but is useful to know how to do. \n",
    "\n",
    "Here are all our columns (I turned them into a list for easy reading)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc82c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(permits_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6ae4fc",
   "metadata": {},
   "source": [
    "We probably don't care about a number of those partiular columns, so let's drop them.\n",
    "\n",
    "It's best practice to make a copy of your dataframe before you start changing it, so we'll start with that: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "438b6e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "permits_df_copy = permits_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58593355",
   "metadata": {},
   "source": [
    "Then we can drop several of those columns using drop(). Here's some info about what we're doing:\n",
    " * drop() elimates columns\n",
    " * You have to tell it what column names you want to drop, this can be passed as a list \n",
    " * You need to tell it you're dropping a column (not a row) which is axis = 1 (axis = 0 is for rows)\n",
    " * inplace = True makes sure this affects the dataframe; otherwise, it would create a copy of the dataframe where the change happens \n",
    "\n",
    "I've dropped two columns below, try adding another column name to the list that we don't need! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5e1822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "permits_df_copy.drop([\"CommunityBoard(s)\", \"PolicePrecinct(s)\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce8e418",
   "metadata": {},
   "source": [
    "**Doing the analysis**\n",
    "\n",
    "We need to take the next four steps to answer our RQ:\n",
    "  * isolate the two columns that have our information (EventType and Borough)\n",
    "  * use value_counts() which helps us aggregate values in columns\n",
    "  * convert this into it's own dataframe using reset_index()\n",
    "  * sort the columns for easier viewing using sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7f03b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate our two columns:\n",
    "\n",
    "rq_df = permits_df_copy[[\"EventType\", \"Borough\"]]\n",
    "rq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a259e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the values\n",
    "#this LOOKS like it is a dataframe, but it's actually a series\n",
    "\n",
    "rq_df = rq_df.value_counts()\n",
    "rq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ad270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset the index to transform it into a dataframe\n",
    "\n",
    "rq_df = rq_df.reset_index()\n",
    "rq_df.columns = [\"Event\", \"Borough\", \"Count\"] #names columns\n",
    "rq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd9588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rq_df.sort_values(\"Event\", inplace = True, ascending = False) \n",
    "rq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49b225a",
   "metadata": {},
   "source": [
    "It's your turn! \n",
    "\n",
    "Try to answer this research question: *Which borough distributed the most permits?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c656bf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b01b63",
   "metadata": {},
   "source": [
    "#### Section 2: Our Second Dataset \n",
    "\n",
    "You can find our second dataset [here](https://drive.google.com/file/d/1RgcK9VPCIxVMDZabQAJhWCp7z0LD_Im3/view?usp=sharing). It has information about the top 1000 ranking movies on IMDB. Please download that and bring it into your working directory.\n",
    "\n",
    "Oftentimes online movie ratings have a recency bias -- that is, the more recently a movie was made, the more likely it is to have a high review because people have just seen it. That leads us to ask a few questions: *How many different years are represented in this dataset? Which years have the highest number of movies associated with them? And of those years, are most of them after 2000?* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6f45d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "film_df = pd.read_csv(\"imdb_top_1000 (1).csv\")\n",
    "film_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0300e2",
   "metadata": {},
   "source": [
    "**Cleaning data three different ways**\n",
    "\n",
    "There's actually an error in our dataset that is going to create an issue for us. Do you notice that the Release_Year column is an object datatype? You wouldn't expect that because it should *in theory* all be numbers. What I found is that one singular row has the string \"PG\" in it instead of a year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5112ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PG\n"
     ]
    }
   ],
   "source": [
    "#proof that we have one singular string in our Released_Year column\n",
    "\n",
    "for i in film_df[\"Released_Year\"].to_list():\n",
    "    if i.isalpha():\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6828c462",
   "metadata": {},
   "source": [
    "*Using loc[]*\n",
    "\n",
    "I can use loc[] (which we learned above) to isolate this row because I know the value (pandas calls this a label). Remember: loc[] lets us access rows and columns by the label! This then shows me the index. I can then use the index to drop that row from my dataset.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778b695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "film_df.loc[film_df[\"Released_Year\"] == \"PG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f135d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#notice that we only have 999 rows now compared to before!\n",
    "\n",
    "film_df_copy = film_df.drop(966)\n",
    "film_df_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f937e9",
   "metadata": {},
   "source": [
    "*Using isin()*\n",
    "\n",
    "This looks for a list of values in the row, and if they ARE present, it drops them. Notice that we're isolating the appropriate column, using .isin() to pass a list of values (in this case, we only had one value!), and only keep the rows that do NOT have those values in them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b678929",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "film_df_copy_2 = film_df[film_df[\"Released_Year\"].isin([\"PG\"]) == False]\n",
    "film_df_copy_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4159f6",
   "metadata": {},
   "source": [
    "*Flexible solution with notna()*\n",
    "\n",
    "There is an inherent limitation to the previous two solutions: if we have more than one row with alphabetical characters, and those are different, it becomes quite tedious! This is called *hard coding*, where you create a very inflexible bit of code that only works for one singluar situation. Generally, you want to build flexible code that can handle multiple situations. \n",
    "\n",
    "Thus, the better, and more flexible, method would be to simply drop the rows if they contained alphabetical characters. This produces the same effect as above, but would work with ANY row that contained alphabetical characters. \n",
    "\n",
    "Here's a breakdown:\n",
    "  * We isolated the Released_Year column and try to convert each value to a number using to_numeric(). If that value cannot be converted, it becomes NaN. This means Not A Number and is pandas version of \"None\" or \"Null\".\n",
    "  * the function notna() in pandas returns a True Boolean for any value that isn't NAN\n",
    "  * this construction automatically keeps only the rows where notna() returned a True Boolean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea3a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "film_df = film_df[pd.to_numeric(film_df[\"Released_Year\"], errors=\"coerce\").notna()]\n",
    "film_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa9d062",
   "metadata": {},
   "source": [
    "Importantly, that column is STILL listed as an object datatype, we have to take the final step to convert it into an int64 datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c0910c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "film_df = film_df.astype({\"Released_Year\": \"int64\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9773088",
   "metadata": {},
   "source": [
    "Now we can answer our RQ! It turns out that there are 100 years of movies represented in this dataset, but 17 out of the 20 top-rated movies come from after 2000. So I would definitely say it has a recency bias!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b7e18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new dataframe\n",
    "year_aggregate = film_df[\"Released_Year\"].value_counts()\n",
    "year_aggregate = year_aggregate.reset_index()\n",
    "year_aggregate.columns = [\"Release Year\", \"Number of Movies\"]\n",
    "\n",
    "year_aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526e12ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate top 20\n",
    "top_20 = year_aggregate.head(20)\n",
    "top_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ffa3af91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Release Year        17\n",
       "Number of Movies    17\n",
       "dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#boolean masking\n",
    "condition_1 = top_20[\"Release Year\"] >= 2000\n",
    "final_df = top_20[condition_1]\n",
    "final_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d75c8c",
   "metadata": {},
   "source": [
    "Now that we've done ALL that, we can also evaluate which release year has the highest rating on average to see if there's a bias that way. There doesn't seem to be one!\n",
    "\n",
    "Here's what groupby() does:\n",
    "  * It groups rows in a dataframe based on the values of one or more columns. In this case, we're grouping the release year column by the IMDB rating. \n",
    "  * Notice the syntax, we are grouping the rows in the Released_Year column and we're taking the mean (average) IMDB rating for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0b88ef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rating = film_df.groupby(\"Released_Year\")[\"IMDB_Rating\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7eac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rating_df = avg_rating.reset_index()\n",
    "avg_rating_df.columns = [\"Year\", \"Avg_Rating\"]\n",
    "\n",
    "avg_rating_df.sort_values(\"Avg_Rating\", inplace = True, ascending = False) \n",
    "avg_rating_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b944058b",
   "metadata": {},
   "source": [
    "If you understand this recency bias, you could isolate only the rows that come from before 2000 and do your analysis excluding more recent movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ab3943",
   "metadata": {},
   "outputs": [],
   "source": [
    "film_df.loc[film_df[\"Released_Year\"] < 2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa62d31",
   "metadata": {},
   "source": [
    "We could similarly choose to only look at movies from a particular decade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196e8365",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = film_df[\"Released_Year\"]\n",
    "\n",
    "film_df.loc[(column >= 1980) & (column <= 1989)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf85d7e4",
   "metadata": {},
   "source": [
    "#### Section 3: Your turn!\n",
    "\n",
    "You are going to continue to use the IMDB dataset to answer the question *what is the average IMDB rating of the top 10 directors (by frequency) represented in the dataset?*\n",
    "\n",
    "  To answer this:\n",
    "\n",
    "  *   First, isolate the top 10 directors (as a hint: Alfred Hitchcock is number one)\n",
    "  *   Like we did above, convert that information into a dataframe.\n",
    "  *   Isolate the column with the directors in it and convert it into a list using [tolist()](https://www.geeksforgeeks.org/python-pandas-series-tolist/).\n",
    "  *   I want you to adapt the syntax that we learned above to strip PG out of the dataframe. You want to create a new copy of the dataframe and strip all directors out of it except those in the list we just created.\n",
    "  *   Finally, you can use groupby() to figure out what the average IMDB score is for those director's movies.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
